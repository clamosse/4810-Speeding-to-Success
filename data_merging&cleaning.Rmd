---
title: "data_merging/cleaning"
output: html_document
date: "2025-03-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(fuzzyjoin)
library(tidyverse)
library(plotly)
library(janitor)
library(corrplot)
library(fastDummies)
library(mice)
library(naniar)
library(car)
library(glmnet)
library(lme4)
library(caret)
```



read files
```{r}
player_play <- read.csv('data/BDB-2025-data/player_play.csv')
players <- read.csv('data/BDB-2025-data/players.csv')
plays <- read.csv('data/BDB-2025-data/plays.csv')
combine <- read.csv('data/filtered_combine.csv')
```

get all route runners from weeks 1-9
```{r}
player_play |> 
  filter(
    !is.na(wasRunningRoute),
    wasRunningRoute == 1
  ) |>
  dplyr::select(nflId) |> 
  group_by(nflId) |> 
  summarize(n_routes = n()) |> 
  left_join(
    y = players,
    by = "nflId"
  ) -> route_runners


route_runners <- route_runners %>%
  separate(height, into = c("feet", "inches"), sep = "-", convert = TRUE) %>%
  mutate(total_inches = feet * 12 + inches) %>%
  select(-feet, -inches) %>% 
  filter(position %in% c('TE','WR','RB'))

write.csv(route_runners %>% select(nflId), "data/route_runner_Ids.csv", row.names = FALSE)
```



all route runners + combine stats 
```{r}
route_runners_combine <- stringdist_left_join(
  x = route_runners,
  y = combine,
  by = c('displayName' = 'Player'),
  distance_col = 'string_dist'
) %>% select(nflId,n_routes,position,displayName, weight, X40yd, X3Cone, Shuttle, total_inches)

route_runners_combine <- dummy_cols(route_runners_combine, select_columns = "position", remove_first_dummy = F, remove_selected_columns = T)
```


looking at how missing values correlate with players performance (measured by number of routes ran)
```{r}
# all players with missing values
# 279
missing_value_players <- route_runners_combine %>% filter(if_any(everything(), is.na))
count(missing_value_players)

# players with no missing values
# 193
full_data_players <- route_runners_combine %>% drop_na()
count(full_data_players)

# players with 2 or less missing values
# 314
two_missing_max <- route_runners_combine %>% filter(rowSums(is.na(.)) <= 2)
count(two_missing_max)

# players with no combine speed stats
# 158
all_missing <- route_runners_combine %>% filter(rowSums(is.na(.)) == 3)
count(all_missing)

df1 <- route_runners_combine %>% select(n_routes) %>% mutate(cat = 'all players')
df2 <- full_data_players %>% select(n_routes) %>% mutate(cat = "0 missing")
#df3 <- missing_value_players %>% select(n_routes) %>% mutate(cat = "1,2,3 missing")
df4 <- two_missing_max %>% select(n_routes) %>% mutate(cat = "up to 2 missing")
df5 <- all_missing %>% select(n_routes) %>%  mutate(cat = "all 3 missing")


df_combined <- bind_rows(df1,df2,df4,df5)
                         
df_combined$cat <- factor(df_combined$cat, levels = c("all players", "0 missing", "up to 2 missing", 'all 3 missing'))

# Create the violin plot
p = ggplot(df_combined, aes(x = cat, y = n_routes, fill = cat)) +
  geom_violin(trim = FALSE) + 
  scale_y_continuous(expand = c(0, 0)) +
  theme_minimal() +
  labs(title = "Missing Speed Combine Stats vs Reciever Preformance", y = "Preformance (num routes)", x = "Number of missing combine speed stats") +
  theme(legend.position = "none")

p

ggsave("Pre Exploratory Graphs/Effects of missing combine values on preformance.png", plot = p, width = 8, height = 6, dpi = 300)
```
we see that players that are missing 2 values or less have a very similar distribution of number of routes ran as players that have no missing values

```{r}

all_players <- as.numeric(unlist(df1['n_routes']))
full_combine_players <- as.numeric(unlist(df2['n_routes']))
missing_2_max_combine <- as.numeric(unlist(df4['n_routes']))


hist(all_players)
hist(full_combine_players)
hist(missing_2_max_combine)

wilcox.test(full_combine_players, missing_2_max_combine, paired = FALSE)

wilcox.test(full_combine_players, all_players, paired = FALSE)


```
we see that there is not a statistically significant difference in the number of routes ran (and by proxy receiver performance) between players with all speed combine stats recorded and players with missing a max of 2 speed combine stats recorded. however there is a statistically significant difference in the number of routes ran (and by proxy receiver performance) between players with all speed combine stats recorded and players with 0 speed combine stats recorded.




when imputing data we want to impute as little of our data as we can, if we use the all players we will be imputing a lot of data, for example 57% of the 3 cone data. however if we limit ourselves to players missing 2 drills we can limit how much data has to be imputed by almost 2/3s.
```{r}
colMeans(is.na(route_runners_combine))
colMeans(is.na(two_missing_max))

sum(is.na(route_runners_combine))
sum(is.na(two_missing_max))


#vif_values <- vif(lm(y ~ ., data = two_missing_max, na.action = na.omit))
#vif_values


mcar_test(two_missing_max %>% select(c('weight','X40yd','X3Cone','Shuttle','total_inches')))


imputed_df <- mice(two_missing_max %>% select(c('weight','X40yd','X3Cone','Shuttle','total_inches')), method = "cart")
plot(imputed_df)
densityplot(imputed_df)


imputed_rr_combine <- complete(imputed_df)

#merge back all other variables not used in imputation
imputed_rr_combine <- (cbind(two_missing_max %>% select(-c('weight','X40yd','X3Cone','Shuttle','total_inches')),imputed_rr_combine))

```
in the MCAR test we get a high p value (.35) so can say we have significant evidence to say our data is 'Missing Completely at Random'




looking at how values (and missing values) may be correlated in the full data, is there correlation with missing values? for example, do we see a positive correlation between missing values and player performance (measured by number of routes run)
```{r}

route_runners_combine$missing40yd <- ifelse(is.na(route_runners_combine$X40yd), 1, 0)
route_runners_combine$missing3Cone <- ifelse(is.na(route_runners_combine$X3Cone), 1, 0)
route_runners_combine$missingShuttle <- ifelse(is.na(route_runners_combine$Shuttle), 1, 0)

```


```{r}
cor_matrix <- cor(route_runners_combine %>% select(where(is.numeric)), use = "pairwise.complete.obs")

pdf("Pre Exploratory Graphs/correlation_plot.pdf")
corrplot(cor_matrix, method = "circle")

dev.off()

corrplot(cor_matrix, method = "circle")

```

our first data set is 'route_runners_combine' which is all route runners and their combine stats, with this we will likely do separate analysis on each combine stat in a way to deal with missing values)

our second data set is 'imputed_rr_combine' which includes only route runners who have 2 or less missing combine values, then all the missing values are imputed
```{r}

route_runners_combine

write.csv(route_runners_combine, "data/route_runners_combine.csv", row.names = FALSE)

imputed_rr_combine <- imputed_rr_combine %>% select(-c('missing40yd','missing3Cone','missingShuttle'))

```



```{r}
player_aggregated_openess <- read.csv('data/player_aggregated2.csv')

hist(player_aggregated_openess$mean)
```


```{r}

scaled_data <- imputed_rr_combine %>% mutate_at(c("weight", "total_inches", "X40yd","X3Cone","Shuttle"), ~(scale(.) %>% as.vector))


double_mean_openess_and_combine <- right_join(
  x = player_aggregated_openess,
  y = imputed_rr_combine,
  by = c('nflId'),
) %>% filter(count >= 1) %>% select(-c('count','n_routes','displayName'))

# can also look at bmi as height and weight are highly colinear, however we can see diffrent results for height and weight when looking at positions, ie. for one position we see you want to be shorter and heavier, but for another you want to be taller and heavier

# double_mean_openess_and_combine <-  double_mean_openess_and_combine %>% mutate(BMI = (weight / total_inches ^2)) %>% select(-c('weight','total_inches'))

scaled_data <- double_mean_openess_and_combine %>% mutate_at(c("weight","total_inches", "X40yd","X3Cone","Shuttle"), ~(scale(.) %>% as.vector))

write.csv(scaled_data, "data/double_mean_openess_and_scaled_combine.csv", row.names = FALSE)

df_wr <- scaled_data %>% filter(position_WR == 1) %>% select(-c("position_RB","position_TE","position_WR"))
df_rb <- scaled_data %>% filter(position_RB == 1) %>% select(-c("position_RB","position_TE","position_WR"))
df_te <- scaled_data %>% filter(position_TE == 1) %>% select(-c("position_RB","position_TE","position_WR"))


model_wr <- lm(mean ~ . - 1 - nflId, data = df_wr)
model_rb <- lm(mean ~ . - 1 - nflId, data = df_rb)
model_te <- lm(mean ~ . - 1 - nflId, data = df_te)

summary(model_wr)

summary(model_rb)

summary(model_te)


#TODO look into repeated measures regression

```


```{r}
player_per_play_openess <- read.csv('data/play_aggregated2.csv')

player_play
```



```{r}

player_combine_opennes_per_play <- left_join(
  x = player_per_play_openess,
  y = scaled_data,
  by = c('nflId'),
) %>% filter(n_routes >= 1) %>% select(-c(,'X'))


player_combine_opennes_per_play <- left_join(
  x = player_combine_opennes_per_play,
  y = player_play,
  by = c('gameId','playId','nflId'),
)%>% select(c('mean','position_RB','position_TE','position_WR',"weight","X40yd","X3Cone","Shuttle","total_inches","routeRan.y","nflId"))

player_combine_opennes_per_play <- dummy_cols(player_combine_opennes_per_play, select_columns = "routeRan.y", remove_first_dummy = F, remove_selected_columns = T)


fit <- lmer(mean ~ . - nflId + (1 | nflId) - 1, data = player_combine_opennes_per_play)
fit
summary(fit)




```